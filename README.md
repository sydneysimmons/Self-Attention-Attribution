# Self-Attention Attribution: Interpreting Information Interactions Inside Transformer

## Overview:
Attention score refers to the strength of a token's relationship to all other tokens, including itself. Attention scores are calculated for each token in each attention head.

Attention Score:



Attribution Score:



Head Pruning:

<img width="632" alt="Screen Shot 2022-10-28 at 2 45 32 PM" src="https://user-images.githubusercontent.com/89158606/198719755-2c394309-02d2-41dc-8db6-d1e6a8a3e460.png">

## Additional Resources 
Transformer and Self-Attention Review: 
http://jalammar.github.io/illustrated-transformer/
https://arxiv.org/abs/1706.03762

Related Code (Complicated Implementation):
https://github.com/YRdddream/attattr


