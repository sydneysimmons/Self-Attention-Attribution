# Self-Attention Attribution: Interpreting Information Interactions Inside Transformer

## Overview:
Attention score refers to the strength of a token's relationship to all other tokens, including itself. Attention scores are calculated for each token in each attention head.

<p float="left">
  <img src="https://user-images.githubusercontent.com/89158606/198739910-bb8cece6-1c44-4c0b-931c-8b6985a08524.png" width="300" />
  <img src="https://user-images.githubusercontent.com/89158606/198739937-83af4b54-b7be-4bba-bdb3-5a769ec4bafe.png" width="300" /> 
</p>

## Question 1:
Head Pruning:

<img width="632" alt="Screen Shot 2022-10-28 at 2 45 32 PM" src="https://user-images.githubusercontent.com/89158606/198719755-2c394309-02d2-41dc-8db6-d1e6a8a3e460.png">

## Question 2:


## Critical Analysis

What could have been developed further? 
What was overlooked by the authors?

## Additional Resource Links
Transformer and Self-Attention Review: 
http://jalammar.github.io/illustrated-transformer/
https://arxiv.org/abs/1706.03762

Related Code (Complicated Implementation):
https://github.com/YRdddream/attattr

## Video Recording Link
